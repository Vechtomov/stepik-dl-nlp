{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тематическая классификация длинных текстов - TFIDF и LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если Вы запускаете ноутбук на colab или kaggle,\n",
    "# выполните следующие строчки, чтобы подгрузить библиотеку dlnlputils:\n",
    "\n",
    "# !git clone https://github.com/Samsung-IT-Academy/stepik-dl-nlp.git && pip install -r stepik-dl-nlp/requirements.txt\n",
    "# import sys; sys.path.append('./stepik-dl-nlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:42:57.265628Z",
     "start_time": "2019-09-12T12:42:55.188211Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import dlnlputils\n",
    "from dlnlputils.data import tokenize_text_simple_regex, tokenize_corpus, build_vocabulary, \\\n",
    "    vectorize_texts, SparseFeaturesDataset\n",
    "from dlnlputils.pipeline import train_eval_loop, predict_with_model, init_random_seed\n",
    "\n",
    "init_random_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка текстов и подготовка признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:42:57.847399Z",
     "start_time": "2019-09-12T12:42:57.268037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество обучающих текстов 11314\n",
      "Количество тестовых текстов 7532\n",
      "\n",
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "Метка 7\n"
     ]
    }
   ],
   "source": [
    "train_source = fetch_20newsgroups(subset='train')\n",
    "test_source = fetch_20newsgroups(subset='test')\n",
    "\n",
    "print('Количество обучающих текстов', len(train_source['data']))\n",
    "print('Количество тестовых текстов', len(test_source['data']))\n",
    "print()\n",
    "print(train_source['data'][0].strip())\n",
    "\n",
    "print()\n",
    "print('Метка', train_source['target'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DF = 0.8\n",
    "MIN_COUNT = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:43:00.294422Z",
     "start_time": "2019-09-12T12:42:57.849386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from lerxst where thing subject what this nntp posting host rac3 organization university maryland college park lines wondering anyone there could enlighten this other door sports looked from late early called bricklin doors were really small addition front bumper separate from rest body this know anyone tellme model name engine specs years production where this made history whatever info have this funky looking please mail thanks brought your neighborhood lerxst\n"
     ]
    }
   ],
   "source": [
    "train_tokenized = tokenize_corpus(train_source['data'])\n",
    "test_tokenized = tokenize_corpus(test_source['data'])\n",
    "\n",
    "print(' '.join(train_tokenized[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:43:00.825372Z",
     "start_time": "2019-09-12T12:43:00.297392Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных токенов 21628\n",
      "[('that', 0), ('this', 1), ('have', 2), ('with', 3), ('writes', 4), ('article', 5), ('posting', 6), ('host', 7), ('nntp', 8), ('there', 9)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vocabulary, word_doc_freq = build_vocabulary(train_tokenized, max_doc_freq=MAX_DF, min_count=MIN_COUNT)\n",
    "UNIQUE_WORDS_N = len(vocabulary)\n",
    "print('Количество уникальных токенов', UNIQUE_WORDS_N)\n",
    "print(list(vocabulary.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:43:01.524600Z",
     "start_time": "2019-09-12T12:43:00.829107Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(word_doc_freq, bins=20)\n",
    "plt.title('Распределение относительных частот слов')\n",
    "plt.yscale('log');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:44:16.094816Z",
     "start_time": "2019-09-12T12:43:01.526554Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\8FEE~1\\AppData\\Local\\Temp/ipykernel_6516/1024983479.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mVECTORIZATION_MODE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'tfidf'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_vectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorize_texts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_tokenized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_doc_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVECTORIZATION_MODE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtest_vectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorize_texts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_tokenized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_doc_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVECTORIZATION_MODE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Размерность матрицы признаков обучающей выборки'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_vectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Github\\stepik-dl-nlp\\dlnlputils\\data\\bag_of_words.py\u001b[0m in \u001b[0;36mvectorize_texts\u001b[1;34m(tokenized_texts, word2id, word2freq, mode, scale)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword2id\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                 \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtext_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword2id\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# получаем бинарные вектора \"встречается или нет\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Михаил\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\sparse\\_index.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, x)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mINT_TYPES\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mINT_TYPES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Trying to assign a sequence to an item'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "VECTORIZATION_MODE = 'tfidf'\n",
    "train_vectors = vectorize_texts(train_tokenized, vocabulary, word_doc_freq, mode=VECTORIZATION_MODE)\n",
    "test_vectors = vectorize_texts(test_tokenized, vocabulary, word_doc_freq, mode=VECTORIZATION_MODE)\n",
    "\n",
    "print('Размерность матрицы признаков обучающей выборки', train_vectors.shape)\n",
    "print('Размерность матрицы признаков тестовой выборки', test_vectors.shape)\n",
    "print()\n",
    "print('Количество ненулевых элементов в обучающей выборке', train_vectors.nnz)\n",
    "print('Процент заполненности матрицы признаков {:.2f}%'.format(train_vectors.nnz * 100 / (train_vectors.shape[0] * train_vectors.shape[1])))\n",
    "print()\n",
    "print('Количество ненулевых элементов в тестовой выборке', test_vectors.nnz)\n",
    "print('Процент заполненности матрицы признаков {:.2f}%'.format(test_vectors.nnz * 100 / (test_vectors.shape[0] * test_vectors.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:44:16.857114Z",
     "start_time": "2019-09-12T12:44:16.098773Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(train_vectors.data, bins=20)\n",
    "plt.title('Распределение весов признаков')\n",
    "plt.yscale('log');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Распределение классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:44:16.864960Z",
     "start_time": "2019-09-12T12:44:16.859476Z"
    }
   },
   "outputs": [],
   "source": [
    "UNIQUE_LABELS_N = len(set(train_source['target']))\n",
    "print('Количество уникальных меток', UNIQUE_LABELS_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:44:17.106036Z",
     "start_time": "2019-09-12T12:44:16.867310Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(train_source['target'], bins=np.arange(0, 21))\n",
    "plt.title('Распределение меток в обучающей выборке');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:44:17.312198Z",
     "start_time": "2019-09-12T12:44:17.109884Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(test_source['target'], bins=np.arange(0, 21))\n",
    "plt.title('Распределение меток в тестовой выборке');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:44:17.319292Z",
     "start_time": "2019-09-12T12:44:17.315074Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_dataset = SparseFeaturesDataset(train_vectors, train_source['target'])\n",
    "# test_dataset = SparseFeaturesDataset(test_vectors, test_source['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение модели на PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:46:22.371272Z",
     "start_time": "2019-09-12T12:44:17.322178Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model = nn.Linear(UNIQUE_WORDS_N, UNIQUE_LABELS_N)\n",
    "\n",
    "# scheduler = lambda optim: \\\n",
    "#     torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=5, factor=0.5, verbose=True)\n",
    "\n",
    "# best_val_loss, best_model = train_eval_loop(model=model,\n",
    "#                                             train_dataset=train_dataset,\n",
    "#                                             val_dataset=test_dataset,\n",
    "#                                             criterion=F.cross_entropy,\n",
    "#                                             lr=1e-1,\n",
    "#                                             epoch_n=200,\n",
    "#                                             batch_size=32,\n",
    "#                                             l2_reg_alpha=0,\n",
    "#                                             lr_scheduler_ctor=scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:46:25.105663Z",
     "start_time": "2019-09-12T12:46:22.373012Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_pred = predict_with_model(best_model, train_dataset)\n",
    "\n",
    "# train_loss = F.cross_entropy(torch.from_numpy(train_pred),\n",
    "#                              torch.from_numpy(train_source['target']).long())\n",
    "\n",
    "# print('Среднее значение функции потерь на обучении', float(train_loss))\n",
    "# print('Доля верных ответов', accuracy_score(train_source['target'], train_pred.argmax(-1)))\n",
    "# print()\n",
    "\n",
    "\n",
    "\n",
    "# test_pred = predict_with_model(best_model, test_dataset)\n",
    "\n",
    "# test_loss = F.cross_entropy(torch.from_numpy(test_pred),\n",
    "#                             torch.from_numpy(test_source['target']).long())\n",
    "\n",
    "# print('Среднее значение функции потерь на валидации', float(test_loss))\n",
    "# print('Доля верных ответов', accuracy_score(test_source['target'], test_pred.argmax(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Михаил\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Михаил\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Михаил/nltk_data'\n    - 'c:\\\\Users\\\\Михаил\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\nltk_data'\n    - 'c:\\\\Users\\\\Михаил\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\Михаил\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Михаил\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\8FEE~1\\AppData\\Local\\Temp/ipykernel_564/533625681.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"guru99 is a totally new kind of learning experience.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mlemma_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Михаил\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m     \"\"\"\n\u001b[1;32m--> 129\u001b[1;33m     \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m     return [\n\u001b[0;32m    131\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Михаил\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \"\"\"\n\u001b[1;32m--> 106\u001b[1;33m     \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"tokenizers/punkt/{language}.pickle\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Михаил\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    748\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m     \u001b[1;31m# Load the resource.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 750\u001b[1;33m     \u001b[0mopened_resource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    751\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"raw\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Михаил\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"nltk\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 876\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    877\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"file\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    878\u001b[0m         \u001b[1;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Михаил\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Михаил/nltk_data'\n    - 'c:\\\\Users\\\\Михаил\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\nltk_data'\n    - 'c:\\\\Users\\\\Михаил\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\Михаил\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Михаил\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from collections import defaultdict\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "\n",
    "text = \"guru99 is a totally new kind of learning experience.\"\n",
    "tokens = word_tokenize(text)\n",
    "lemma_function = WordNetLemmatizer()\n",
    "for token, tag in pos_tag(tokens):\n",
    "    lemma = lemma_function.lemmatize(token, tag_map[tag[0]])\n",
    "    print(token, \"=>\", lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Альтернативная реализация на scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:46:31.791405Z",
     "start_time": "2019-09-12T12:46:25.107897Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sklearn_pipeline = Pipeline((('vect', TfidfVectorizer(tokenizer=tokenize_text_simple_regex,\n",
    "                                                      max_df=MAX_DF,\n",
    "                                                      min_df=MIN_COUNT)),\n",
    "                             ('cls', LogisticRegression())))\n",
    "sklearn_pipeline.fit(train_source['data'], train_source['target']);\n",
    "sklearn_pipeline_log_reg = sklearn_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "sklearn_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(tokenizer=tokenize_text_simple_regex,max_df=MAX_DF,min_df=MIN_COUNT)),\n",
    "    # ('chi2', SelectKBest(chi2, k=1000)),\n",
    "    # ('nb', MultinomialNB())\n",
    "    ('cls', LogisticRegression())\n",
    "    ])\n",
    "sklearn_pipeline.fit(train_source['data'], train_source['target']);\n",
    "sklearn_pipeline_log = sklearn_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение функции потерь на обучении 2.4954788918622985\n",
      "Доля верных ответов 0.9716280714159449\n",
      "\n",
      "Среднее значение функции потерь на валидации 2.653902258237496\n",
      "Доля верных ответов 0.8190387679235263\n"
     ]
    }
   ],
   "source": [
    "sklearn_train_pred = sklearn_pipeline.predict_proba(train_source['data'])\n",
    "sklearn_train_loss = F.cross_entropy(torch.from_numpy(sklearn_train_pred),\n",
    "                                                 torch.from_numpy(train_source['target']).long())\n",
    "print('Среднее значение функции потерь на обучении', float(sklearn_train_loss))\n",
    "print('Доля верных ответов', accuracy_score(train_source['target'], sklearn_train_pred.argmax(-1)))\n",
    "print()\n",
    "\n",
    "sklearn_test_pred = sklearn_pipeline.predict_proba(test_source['data'])\n",
    "sklearn_test_loss = F.cross_entropy(torch.from_numpy(sklearn_test_pred),\n",
    "                                                torch.from_numpy(test_source['target']).long())\n",
    "print('Среднее значение функции потерь на валидации', float(sklearn_test_loss))\n",
    "print('Доля верных ответов', accuracy_score(test_source['target'], sklearn_test_pred.argmax(-1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "87ca4934905532d15cbd0e1b39f8ec7c82379aae06d4434255c4ab2516c6087a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
